<a href="https://npedraza09.github.io">Back to My Portfolio</a>

<a class="anchor" id="Index"></a>
# Index

- [Abstract](#Abstract)
- [1. Introduction](#Introduction)
- [2. Structure](#Structure)
    - [2.1 Data Extraction](#Extraction)
    - [2.2 Data Pipeline](#Pipeline)
    - [2.3 Data Visualization](#Visualization)
- [3. Code](#Code)
    - [3.1 Extraction](#Code_Extraction)
    - [3.2 Cleaning and Counting](#Cleaning_Counting)
    - [3.3 DAG](#DAG)
    - [3.4 New_File](#New_File)
    - [3.5 Graphing](#Graphing)
- [4. Results](#Results)
- [5. Conclusion](#Conclusion)


<a class="anchor" id="Abstract"></a>
##  Abstract
This project is designed to scrape, clean, and structure MIT course catalog data for word-frequency analysis while showcasing a fully containerized and orchestrated workflow. Leveraging Pythonâ€™s urllib and BeautifulSoup for web scraping, the pipeline transforms raw HTML into structured data and then processes it through Docker and Airflow to ensure efficient and modular task execution. The resulting JSON word counts feed into an interactive JavaScript and D3-based bubble chart, providing a visually engaging overview of course content trends. By integrating Python-driven data ingestion and transformation with front-end data storytelling, this project demonstrates an end-to-end solution for extracting insights from unstructured web data.


[Back to top](#Index)

<a class="anchor" id="Introduction"></a>
## 1. Introduction


[Back to top](#Index)

<a class="anchor" id="Structure"></a>
## 2. Structure

<a class="anchor" id="Extraction"></a>
### 2.1 Data Extraction

### Tools:
* Python
* JavaScript
* HTML
* JSON
* Airflow
* Libraries: urllib, BeautifulSoup, os, D3, and airflow





